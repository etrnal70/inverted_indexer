%!TEX root = ./template-skripsi.tex
%-------------------------------------------------------------------------------
%                     BAB III
%               			PEMBAHASAN
%-------------------------------------------------------------------------------

\chapter{METODOLOGI PENELITIAN}

% Disini jelasin alur gimana dapetin index
\section{Tahapan Penelitian}

Gambar \textit{flowchart} berikut mengilustrasikan proses pembuatan \textit{
inverted index} dari dataset yang ada pada database hingga ke proses pencarian
oleh pengguna.

\begin{figure}[H]
  \centering{}
	\includegraphics[width=0.6\textwidth]{gambar/metode\-penelitian}
  \caption{Flowchart tahapan penelitian modul \textit{indexing}}
\end{figure}

\textit{Modifikasi kode \textit{Telusuri}}

Data utama yang diperlukan oleh modul \textit{indexing} dari database adalah
teks yang berisi bagian informasi inti dari halaman tersebut. Umumnya, sebuah
halaman web memiliki banyak teks diluar informasi inti yang tidak diperlukan.
Oleh karena itu, ditetapkan bahwa modul \textit{indexing} hanya akan mengambil
bagian paragraf dari halaman web. Untuk mengidentifikasi sebuah paragraf, cukup
dengan mencari \textit{tag} HTML yang sesuai (\textit{<p>}).

Walaupun sudah menspesifikasikan \textit{tag} tertentu yang akan digunakan, pada
praktiknya sering ditemukan penggunaan \textit{tag} paragraf diluar informasi
inti halaman web. Selain itu, seringkali ditemukan paragraf yang memiliki
beberapa simbol yang tidak diperlukan seperti karakter \textit{newline}. Untuk
memastikan bahwa modul \textit{indexing} hanya akan membaca paragraf inti saja,
diperlukan \textit{filter} khusus untuk menghindari masuknya informasi yang
tidak diperlukan. Parameter dari penentuan informasi ini cukup beragam, dan akan
diatur sedemikian rupa pada masa pengujian.

Pada kode program mesin pencari yang telah ada saat ini, paragraf yang disimpan
masih memiliki banyak informasi yang tidak diperlukan. Untuk memudahkan
implementasi modul \textit{indexing}, maka proses \textit{filtering} akan
dilakukan pada kode mesin pencari di bagian ekstraksi informasi dari halaman
web. Akan dibuat sebuah table baru yang berisi paragraf inti saja.

\section{Konstruksi Index}

Sebelum proses \textit{indexing} dilakukan, diperlukan sebuah
\textit{hash table} pada memori. \textit{Hash table} digunakan dengan tujuan
untuk menyimpan kata secara unik dalam dokumen. Jika nantinya ditemukan lebih
dari satu kali kemunculan kata dalam dokumen yang sama, \textit{hash table}
dapat melakukan penambahan kepada \textit{value} dari kata tersebut, dan
membentuk suatu rangkaian seperti \textit{linked list}.

% baca webpage dan ekstrak metadata
Proses \textit{indexing} dimulai dengan mengambil seluruh daftar paragraf yang
tersimpan pada database yang diurutkan berdasarkan \textit{docID}. Kemudian,
setiap paragraf akan dipecah berdasarkan karakter spasi menjadi sebuah array
berisi kata. Setiap kata lalu disimpan dalam sebuah hit bersama dengan informasi
tambahan yang ada pada paragraf.

\begin{algorithm}[H]
  \caption{Operasi \textit{sorting} pada \textit{hitlist}}\label{alg:insert}
  \begin{algorithmic}
    \Function{SortHitlist}{$H$}
      \State $sorted \gets false$
      \State $i \gets 0$

      \item[] % line skip

        \Do
          \If{$i = \Call{Len}{H} - 1$}
            \If{$sorted = true$}
              \State $break$
            \Else
              \State $i \gets 0$
            \EndIf
          \EndIf

          \item[] % line skip

          \State $tempHit \gets H[i]$

          \item[] % line skip

          \If{$H[i].text > H[i+1].text$ OR
          \newline \hspace*{3.8em}$H[i].docID > H[i+1].docID$ OR
          \newline \hspace*{3.8em}$H[i].oset > H[i+1].oset$}
            \State $H[i] \gets H[i+1]$
            \State $H[i+1] \gets tempHit$
          \EndIf

          \item[] % line skip

          \State $i \gets i+1$
        \doWhile{$sorted = false$}

        \item[] % line skip

      \State \Return
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{Algoritma pembuatan index}\label{alg:index}
  \begin{algorithmic}
    \State $hitData \gets \Call{HitData}{false}$ \Comment{Inisiasi \textit{hash table}
    untuk \textit{plain} dan \textit{fancy hit}}
    \State $hitDataAnc \gets \Call{HitData}{true}$

    \item[] % line skip

    \State $docIDList \gets [..]$
    \State $pageLinking \gets [..]$
    \State $words \gets [..]$

    \item[] % line skip

    \State $docs[..] \gets \Call{GetParagraphs}{$$}$ \Comment{Paragraf dari
    \textit{database}}
    \For{$doc \in \mathcal{} docs[..]$}
      \State $docID \gets \Call{Hash}{$$doc.url, doc.crawledAt$$}$
      \State $docList \gets \Call{Append}{$$docList$$, $$docID$$}$
      \State $words[..] \gets \Call{GetWords}{$$doc$$}$ \Comment{Kata beserta
        informasinya}

      \item[] % line skip

      \For{$word \in \mathcal{} words[..]$}
        \If{$word.url \not = nil$}
          \State $pageLinking \gets \Call{Append}{\{$$doc.url$$, $$word.url$$, $$word$$\}}$
          \State $\Call{StoreHit}{$$hitDataAnc$$, $$word$$}$
        \Else
          \State $\Call{StoreHit}{$$hitData, word$$}$
        \EndIf
      \EndFor
    \EndFor

    \item[] % line skip

    \State $(W, H) \gets \Call{Split}{$$hitData$$}$
    \State $(W_{anchor}, H_{anchor}) \gets \Call{Split}{$$hitDataAnc$$}$
    \State $lexicon \gets \Call{Append}{$$lexicon$$, $$W$$}$
    \State $lexicon \gets \Call{Append}{$$lexicon$$, $$W_{anchor}$$}$
    \State $links \gets \Call{Convert}{$$anchors$$}$ \Comment{Konversi
    \textit{anchors} menjadi pasangan \textit{docID}}
  \end{algorithmic}
\end{algorithm}

Dari proses ekstraksi kosakata beserta data tambahannya, akan didapatkan
\textit{forward index} berupa daftar \textit{hit} dari dokumen.  Daftar
\textit{hit} kemudian didistribusikan ke tempat penyimpanan berdasarkan
jenisnya. Untuk \textit{fancy hit} akan ditempatkan secara khusus pada tempat
penyimpanan yang nantinya akan menjadi sumber pencarian utama. Untuk
\textit{hit} lainnya akan ditempatkan ke tempat penyimpanan umum.

% sorting forward index jadi inverted
Untuk melakukan konversi \textit{forward index} menjadi \textit{inverted index},
dilakukan proses \textit{sorting} pada \textit{forward index}. \textit{Sorting}
dilakukan berdasarkan \textit{id} dari kosakata, kemudian dilanjutkan dengan
\textit{id} dari dokumen, dan diakhiri dengan posisi kata pada dokumen. Hasil
dari proses \textit{sorting} disimpan kembali ke tempat penyimpanan dengan
kondisi sudah menjadi \textit{inverted index}.

\section{Daftar kata umum}

Untuk meningkatkan kualitas hasil pencarian, maka skema pencarian perlu
mengabaikan kata-kata yang bersifat umum. Dari hal tersebut, perlu di dapatkan
daftar kata umum dari daftar kosakata yang telah dibuat oleh modul
\textit{indexing}. Metode yang penulis gunakan untuk mendapatkan kata umum
adalah dengan melakukan \textit{sorting} terhadap seluruh daftar kosakata
berdasarkan tingkat kemunculannya secara global. Kemudian, dengan menggunakan
batasan tertentu, akan diambil sebagian persen dari kata terbanyak yang ada.

Sebagai langkah awal, penulis berencana untuk mengambil sebanyak 1\% kata
teratas sebagai kata umum. Nilai tersebut kemudian akan diatur ulang berdasarkan
hasil \textit{user testing}.

\section{Skema Pencarian}

% NOTE Bikin flowchart proses pencarian

% Parsing query
Berdasarkan input query yang diberikan oleh pengguna, query dipecah menjadi
potongan kata yang digabungkan dengan menggunakan operator \textit{boolean}.
Kemudian, untuk setiap kosakata pada query, dilakukan \textit{scanning} terhadap
daftar kosakata. Pencarian pertama kali dilakukan pada \textit{inverted index}
yang berisi \textit{fancy hit}. Jika tidak ditemukan hasil, maka pencarian akan
dilanjutkan pada daftar \textit{plain hit}.

Untuk setiap kosakata pada daftar kosakata yang sesuai dengan kosakata pada
query, akan di dapatkan rangkaian data berupa \textit{id} dari dokumen tempat
kosakata tersebut, total jumlah \textit{hit} pada dokumen serta seluruh daftar
\textit{hit} yang berhubungan dengan kosakata pada dokumen.

% \lstinputlisting[language=Python, caption=Implementasi struktur data dengan \textit{Python}]{../koding_skripsi/main.py}

Untuk setiap daftar \textit{hit} yang didapatkan, dilakukan \textit{merging}
sehingga tersisa dokumen yang memenuhi query.

\begin{algorithm}[H]
  \caption{Proses pengolahan dan pencarian \textit{query}}
  \begin{algorithmic}
    \Function{MergeHitlist}{$p1$, $p2$}
    \State $M \gets [..]$
    \While{$p1 \not = nil$ AND $p2 \not = nil$}
      % TODO Handle multiline
      \If{$p1.docID = p2.docID$} \Comment{Cek kesamaan \textit{docID}}
        \If{$-(p1.oset - p2.oset)$ = 1} \Comment{Cek selisih offset}
          \State \Call{Append}{$M$, $p1$}
        \EndIf
      \EndIf
      \State $p1 \gets \Call{next}{$p1$}$
      \State $p2 \gets \Call{next}{$p2$}$
    \EndWhile{}
    \State \Return $M$
    \EndFunction

    \item[] % line skip

    \State $H \gets [..]$
    \State $W \gets \Call{ParseQuery}{query}$ \Comment{Pecah query menjadi
    daftar kata}
    \For{$w \in \mathcal{} W$}
      \State $h \gets \Call{GetHitlist}{w}$ \Comment{Cari nilai $w$ pada daftar
      kosakata secara sekuensial}
      \If{$h = nil$}
        \State continue
      \EndIf
      \State \Call{Append}{H, h}
    \EndFor

    \item[] % line skip

    \State $i \gets 0$
    \While{$i \not = \Call{Len}{H}$}
      \State $H[0] = \Call{MergeHitlist}{$H[0]$, $H[i]$}$
      \State $i \gets i + 1$
    \EndWhile

    \item[] % line skip

    \State $result \gets \Call{GetResult}{H[0]}$
  \end{algorithmic}
\end{algorithm}

\section{Metode Pemeringkatan}

Dari hasil rangkaian \textit{hit} yang didapatkan, perlu dilakukan beberapa
operasi untuk mendapatkan urutan hasil dokumen yang paling sesuai. Hasil
peringkat yang didapatkan dilakukan berdasarkan dua faktor berikut

\begin{itemize}
  \item{\textit{Word similarity ($\beta$)}, yaitu kemunculan hasil yang memenuhi beberapa
    bagian dari query}
  \item{\textit{Word distance ($\gamma$)}, yaitu jarak kata yang memenuhi query}
\end{itemize}

\subsection{\textit{Word similarity ($\beta$)}}

\textit{Word similarity} menilai suatu kata berdasarkan kemiripannya dari kata
pada query. Untuk membandingkan apakah suatu kata memiliki makna atau maksud
yang sama dengan kata lainnya, akan digunakan \textit{Jaccard distance}.
Perbandingan akan dilakukan berdasarkan hasil kombinasi pada seluruh karakter
yang ada pada kosakata untuk membuat pasangan dua huruf.

Karena \textit{Jaccard distance} mengukur nilai ketidakmiripan dari dua model,
maka tinggi nilai $\beta$ maka nilai dokumen akan semakin rendah.

% TODO Contoh perbandingan dengan Jaccard

\subsection{\textit{Word distance ($\gamma$)}}

Perhitungan \textit{word distance} digunakan untuk melakukan validasi terhadap
urutan kata yang muncul pada dokumen. Urutan dari kata berpengaruh terhadap
maksud dari query. Selain itu, jarak yang terlalu jauh antara kata yang
ditemukan dapat mengurangi relevansi informasi.

Untuk membandingkan jarak kata, seluruh kata pada query perlu diberikan urutan
yang sesuai dengan menggunakan angka terlebih dahulu. Setelah \textit{hitlist}
didapatkan, posisi dari kata yang ditemukan akan dikurangi dengan posisi asli
pada query. Nilai dari dokumen bisa didapatkan dengan rumus

\begin{equation}
  D = (|(L_1 - \acute{L_1})| + |(L_2 - \acute{L_2})| + ... + |(L_n - \acute{L_n})|) - ((L_1 - \acute{L_1}) \times N)
\end{equation}

dimana

\begin{conditions}
  N & Jumlah kata pada query \\
  L_n & Posisi awal kata ke-$n$ pada query \\
  \acute{L_n} & Posisi kata ke-$n$ pada query di dokumen
\end{conditions}

\subsection{Rumus akhir}

Dari seluruh faktor prioritas diatas, maka nilai dari suatu dokumen bisa
didapatkan dengan rumus

\begin{equation}
  \text{TODO Rumus akhir} \\
  D = \lambda_1 S + \lambda_2 S + ... + \lambda_n S
\end{equation}

dimana

\begin{conditions}
  D & Skor dokumen \\
  N & Jumlah kata pada query \\
  Q_n & Query ke-$n$ \\
\end{conditions}

\section{Alat dan Bahan Penelitian}

Pada penelitian ini, terdapat beberapa alat yang digunakan sebagai penunjang
dalam pembuatan modul \textit{indexing} dengan rincian sebagai berikut:

\begin{itemize}
  \item{Laptop HP Elitebook 840 G5 (Intel Core i5-8250U, 16GB RAM)}
  \item{Sistem operasi \textit{Linux}}
  \item{\textit{Neovim} sebagai \textit{code editor}}
  \item{\textit{Podman} untuk menjalankan database \textit{MySQL}}
  \item{Python 3.10}
\end{itemize}

\section{Tahapan Pengembangan}

\subsection{Meningkatkan kemampuan modul \textit{indexing} saat ini}

Pencarian akan dilakukan secara sekuensial terhadap daftar index yang telah
dihasilkan oleh modul \textit{indexing}. Sebagai pembanding, hasil dari
penelitian ini akan digabungkan dengan hasil penelitian Zaidan berjudul \textit{
PERANCANGAN MODUL PENGINDEKS PADA SEARCH ENGINE BERUPA GENERALIZED SUFFIX TREE
UNTUK KEPERLUAN PEMERINGKATAN DOKUMEN}.

Hasil penelitian tersebut menghasilkan modul \textit{indexing} dengan bentuk
\textit{Generalized Suffix Tree (GST)}. Penggunaan modul \textit{GST} dapat
langsung memberikan hasil berupa dokumen tempat kata tersebut berada. Dengan
demikian, modul index pada penelitian ini hanya perlu menunjukkan lokasi kata
pada dokumen melalui informasi yang ada pada \textit{hit}.

Tetapi karena hasil penelitian Zaidan masih memiliki kendala ketika dilakukan
ujicoba secara independen oleh penulis, maka akan dilakukan implementasi ulang
dengan menggunakan modul \textit{GST} yang tersedia di internet.

% TODO Flowchart kalo misalnya jadi pake GST

\subsection{Integrasi pada arsitektur \textit{Telusuri}}

Modul \textit{indexing} akan diintegrasikan dengan mesin pencari
\textit{Telusuri} dalam bentuk API. Hal ini dikarenakan modul ini akan terlibat
dalam proses pemeringkatan hasil pencarian.

% TODO Buat menjelaskan tentang skema pengujian apa yang akan digunakan
% biar ketauan kalo penelitiannya berguna
% \section{Pengujian}
