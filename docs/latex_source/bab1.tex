%!TEX root = ./template-skripsi.tex
%-------------------------------------------------------------------------------
% 								BAB I
% 							LATAR BELAKANG
%-------------------------------------------------------------------------------

\chapter{PENDAHULUAN}

\section{Latar Belakang Masalah}

% Intro
Mesin pencari atau \emph{search engine} adalah program komputer yang digunakan 
untuk melakukan pencarian situs web. Pada awal kemunculannya, mesin pencari
lebih diperuntukkan bagi kalangan akademisi untuk mencari jurnal atau dokumen
akademik lainnya. Namun, seiring dengan meluasnya adopsi internet ke berbagai
lapisan masyarakat, mesin pencari memiliki peran yang lebih besar dalam
penggunaan internet. Mesin pencari berubah menjadi sarana utama dalam pencarian
informasi secara umum.

% Sejarah mesin pencari
Bila dilihat dari penggunaannya, mesin pencari bekerja dengan cara mengolah
\emph{query} yang diberikan oleh pengguna dan menampilkan hasil terkait
informasi tertentu di internet yang paling sesuai dengan \emph{query} tersebut.
Tetapi mesin pencari tidak dapat langsung mencari ke seluruh halaman yang ada
pada internet. Mesin pencari membutuhkan database yang berisi informasi pada
halaman yang tersebar di seluruh jaringan internet. 

Ketika internet masih memiliki lingkup pengguna yang kecil, metode pengumpulan
data untuk database mesin pencari masih dilakukan secara manual. \emph{Archie}, mesin
pencari pertama, mengumpulkan data dengan cara mencari daftar situs yang
tersedia secara publik menggunakan protokol \emph{Telnet} dan memperbarui-nya
secara berkala. \emph{Yahoo} pada awal kemunculannya mempekerjakan beberapa
kurator untuk menyortir situs mana yang berkualitas untuk kemudian ditambahkan
secara manual kedalam database. Namun, semakin tingginya adopsi internet membuat
jumlah data pada internet meledak. Hal ini berakibat pada diperlukannya metode
pengumpulan data yang lebih efisien dan metode penerimaan informasi yang lebih
cepat.

% Arsitektur Google
Mesin pencari membutuhkan serangkaian proses yang perlu dilakukan sebelum dapat
menerima \emph{query} terkait informasi tertentu. \emph{Google}, mesin pencari
paling populer saat ini, mempunyai beberapa komponen yang menjalankan tugas
secara spesifik. Pendiri \emph{Google}, Sergey Brin dan Lawrance Page,
mengungkapkan detail dari arsitektur yang digunakan dalam sebuah paper yang di
rilis pada tahun 1998 dengan judul
\textit{The Anatomy of a Large-Scale Hypertextual Web Search Engine}. Arsitektur
\emph{Google} terdiri dari beberapa komponen utama seperti \emph{crawler},
modul \emph{indexer}, modul pemeringkatan \emph{PageRank} dan modul pencari.
Seluruh modul tersebut dibuat secara mandiri tanpa menggunakan aplikasi atau
layanan pihak ketiga.

Implementasi ulang arsitektur \emph{Google} secara menyeluruh cukup sulit
dilakukan karena banyak detail dari arsitektur yang tidak tercantum dalam paper.
Selain itu \emph{Google} juga banyak membuat implementasi yang telah
dioptimalkan untuk kebutuhan mesin pencari baik dari segi performa maupun
penggunaan media penyimpanannya, tanpa mempublikasikan kode program atau
algoritma yang digunakan.

% Arsitektur Telusuri
Upaya implementasi ulang arsitektur \emph{Google} telah dilakukan oleh Lazuardy
Khatulistiwa dalam penelitiannya yang berjudul \emph{PERANCANGAN ARSITEKTUR
SEARCH ENGINE DENGAN MENGINTEGRASIKAN WEB CRAWLER, ALGORITMA PAGE RANKING, DAN
DOCUMENT RANKING}. Arsitektur tersebut merupakan pengembangan dari penelitian
yang dilakukan oleh Muhammad Fathan dengan judul
\textit{PERANCANGAN CRAWLER SEBAGAI PENDUKUNG PADA SEARCH ENGINE} yang
menghasilkan \emph{web crawler}. \emph{Web crawler} bertugas mengumpulkan
halaman web berdasarkan \emph{entrypoint} tertentu.  Halaman web tersebut
kemudian di ekstrak dan dikumpulkan daftar kata yang termuat pada halaman web
tersebut serta \emph{outgoing link} yang merujuk kepada halaman web lain. Kedua
data tersebut kemudian disimpan pada database \emph{MySQL}.

Data yang tersimpan pada database selanjutnya di proses oleh modul
\emph{PageRank}. Modul \emph{PageRank} menghitung peringkat suatu halaman web
berdasarkan seberapa banyak halaman web lain yang merujuk kepada halaman web
tersebut. Setelah kalkulasi peringkat halaman, data akan diolah oleh modul
\emph{TF-IDF}. Modul \emph{TF-IDF} akan menghitung bobot kata pada dokumen
berdasarkan frekuensi kemunculan kata tersebut dalam suatu dokumen tertentu dan
jumlah dokumen yang mengandung kata tersebut. Hasil perhitungan skor dari modul
\emph{PageRank} dan \emph{TF-IDF} kemudian akan digabungkan dengan menggunakan
algoritma \emph{similarity scoring} yang akan menghasilkan skor relevansi suatu
halaman.

% Kekurangan dari arsitektur existing terutama pada bagian indexing
Hasil riset yang telah dilakukan oleh Lazuardy masih memiliki kekurangan, dan
implementasinya juga cukup berbeda dibandingkan dengan arsitektur milik
\emph{Google} karena keterbatasan detailnya.  Salah satu modul yang belum
memiliki implementasi yang \textit{proper} adalah modul \emph{indexing}.
\emph{Indexing} adalah suatu proses pemetaan \emph{record} pada database dengan
tujuan mempercepat proses pengambilan \emph{record} dari database dan
meningkatkan output hasil pencarian. Proses \emph{indexing} akan menghasilkan
\emph{index}, yaitu representasi data yang merujuk pada lokasi data yang lebih
lengkap pada database. Singkatnya, konsep \emph{index} pada mesin pencari kurang
lebih sama dengan index yang biasa ditemukan di bagian belakang buku.

% Penjelasan terkait indexing
Representasi data pada \emph{index} memiliki tingkat akurasi lokasi data
(\emph{granularity}) yang dapat diatur, seperti suatu frase dalam suatu
paragraf, atau unit data yang lebih kecil seperti satu kata tertentu saja.
Pemilihan tingkat \emph{granularity} dapat mempengaruhi performa dan akurasi
dari proses pengambilan data. Sebagai contoh, penggunaan \emph{synonym ring}
yang dapat melakukan pengelompokan kata yang bermakna sama seperti
\emph{WordNet} dapat memberikan hasil yang lebih baik dibandingkan dengan hanya
menggunakan potongan kata biasa (\cite{gonzalo1998wordnet}).

% Indexing untuk penyimpanan teks
Terdapat berbagai implementasi \emph{index} yang disesuaikan dengan jenis data
yang disimpan pada database. Mesin pencari membutuhkan implementasi \emph{index}
yang dioptimalkan untuk teks secara menyeluruh. Dalam artikel yang berjudul
\emph{An Efficient Indexing Technique for Full-Text Database Systems}, 
implementasi \emph{index} yang difokuskan kepada penyimpanan teks setidaknya
perlu melakukan tiga hal secara efisien. Yang pertama adalah mendukung
pengambilan dokumen berdasarkan \emph{query} berupa beberapa kata yang
digabungkan oleh operator logika. Yang kedua adalah memiliki kemampuan untuk
menambahkan \emph{record} baru secara efisien. Yang ketiga adalah kemampuan
untuk membuat pemeringkatan terhadap \emph{record} yang ada apabila tidak ada
data yang memenuhi \emph{query} secara penuh (\cite{zobel1992efficient}).

% Prinsip kerja
Dari persyaratan diatas, solusi yang umum digunakan untuk database penyimpanan
teks adalah \emph{inverted file index}. Wujud dari \emph{inverted file index}
adalah daftar yang memuat kata dan posisinya dalam dokumen yang diurutkan
berdasarkan kata.  Untuk mendapatkan daftar kata pada dokumen, dibutuhkan
\emph{lexicon} yang memuat seluruh kata yang muncul pada database
(\cite{hersh2001gigabytes}).

Penelitian tentang struktur data untuk keperluan \emph{indexing} telah dilakukan
oleh Zaidan yang berjudul \emph{Perancangan Modul Pengindeks Pada Search Engine
Berupa Induced Generalized Suffix Tree Untuk Keperluan Perangkingan Dokumen}.
Penelitian tersebut menggunakan \emph{generalized suffix tree} (\emph{GST})
sebagai alternatif dari \emph{inverted index} yang sudah umum digunakan sebagai
stuktur data \emph{index}. \emph{GST} diklaim mampu memberikan performa yang
lebih baik.

% Pross indexing Google
Proses \emph{indexing} yang akan di replika akan menggunakan detail yang
terbatas yang dapat diakses pada \emph{paper Google}.  Untuk memroses
\emph{query}, \emph{Google} melakukan beberapa langkah berikut.  Pertama,
\emph{query} dipotong per kata. Setiap kata kemudian di konversi menjadi
\emph{wordID}, yang dapat mengidentifikasi suatu kata secara unik.

Dari kumpulan \emph{wordID} tersebut, untuk setiap kata akan dicari
kemunculannya pada permulaan daftar \emph{index} yang berisi judul dan
\emph{outgoing links}.  Pencarian dilakukan dengan proses \emph{scanning} secara
menyeluruh pada daftar \emph{index} sampai ditemukan dokumen yang memenuhi
seluruh kata pada \emph{query}. Untuk setiap dokumen yang ditemukan, akan
dihitung skor dokumen berdasarkan \emph{query} yang ada.

Jika telah sampai pada akhir daftar dokumen dan posisi pencarian berada pada
daftar judul dan \emph{outgoing links}, maka posisi akan berpindah ke daftar
kata pada seluruh dokumen, dan mulai melakukan pencarian dokumen lagi. Tetapi
jika belum mencapai akhir daftar dokumen, maka posisi pencarian akan diulang
dari posisi awal dan memulai pencarian lagi. Setelah seluruh daftar
\emph{index} dikunjungi, nantinya akan diakhiri dengan mengurutkan dokumen
berdasarkan skor.

Arsitektur yang dibuat saat ini menggunakan algoritma \emph{similarity scoring}
untuk mendapatkan nilai relevansi suatu halaman, dengan rumus:

\begin{equation}
	W = \alpha{} \cdot{} PR + \beta{} \cdot{} QR
\end{equation}

Dimana $W$ adalah skor relevansi suatu halaman, $\alpha{}$ adalah konstanta yang
bernilai $0.4$, $PR$ adalah nilai dari \emph{PageRank}, $\beta{}$ adalah
konstanta yang bernilai $0.6$ dan $QR$ adalah skor pemeringkatan \emph{query}
yang menggabungkan beberapa algoritma dengan rumus:

\begin{equation}
	QR = \beta{}_1 \cdot{} QR_1 + \cdots{} + \beta{}_N \cdot{} QR_N
\end{equation}

Dimana $QR_N$ dapat berupa hasil dari algoritma \emph{query ranking} yang
digunakan seperti \emph{TF-IDF} atau \emph{Skipgram}.

Implementasi dari proses \emph{indexing} nantinya dapat berperan sebagai
metode \emph{query ranking} yang berbeda, atau melakukan enkapsulasi nilai
\emph{query ranking} yang sudah ada.

\section{Rumusan Masalah}
Berdasarkan uraian pada latar belakang yang di utarakan di atas, maka perumusan
masalah pada penelitian ini adalah '\textbf{penambahan fungsi \textit{indexing}
pada mesin pencari melalui \textit{inverted index} untuk meningkatkan performa
waktu pencarian'}.

\section{Pembatasan Masalah}
Pembatasan masalah pada penelitian ini adalah pembuatan sebagian arsitektur
mesin pencari yaitu \emph{indexing}. Sistem \emph{indexing} yang akan dibuat
mengacu pada konsep arsitektur \emph{Google} awal. Selain itu, implementasi
sistem \textit{indexing} ini hanya akan mencakup proses konstruksi awal index
berdasarkan data yang sudah dikumpulkan oleh \textit{crawler}.

\section{Tujuan Penelitian}
\begin{enumerate}
	\item Memahami arsitektur mesin pencari.
	\item Memahami cara kerja proses \emph{indexing}.
	\item Membuat implementasi \emph{indexing} untuk memenuhi kebutuhan mesin
		pencari.
\end{enumerate}

\section{Manfaat Penelitian}
\begin{enumerate}
	\item Bagi penulis
		
	Menambah pengetahuan dibidang \emph{information retrieval} khususnya mengenai
		\emph{search engine} dan \emph{crawling}, mengasah kemampuan
		\emph{programming}, dan memperoleh gelar sarjana dibidang Ilmu Komputer.
		Selain itu, penulisan ini juga merupakan media bagi penulis untuk
		mengaplikasikan ilmu yang didapat di kampus ke kehidupan masyarakat.
		
	\item Bagi Universitas Negeri Jakarta
	
	Menjadi pertimbangan dan evaluasi akademik khususnya Program Studi Ilmu
		Komputer dalam penyusunan skripsi sehingga dapat meningkatkan kualitas
		akademik di program studi Ilmu Komputer Universitas Negeri Jakarta serta
		meningkatkan kualitas lulusannya.
			
\end{enumerate}

% Baris ini digunakan untuk membantu dalam melakukan sitasi
% Karena diapit dengan comment, maka baris ini akan diabaikan
% oleh compiler LaTeX.
\begin{comment}
\bibliography{daftar-pustaka}
\end{comment}
